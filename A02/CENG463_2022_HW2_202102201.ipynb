{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Joel Amarou Heuer\n",
    "\n",
    "Student ID: 202102201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/korosu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import nltk # for tokenization use nltk\n",
    "nltk.download('punkt')\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Hyper-)Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "output_size = 1 # since it is regression problem, only 1 output neuron\n",
    "learning_rate = 0.01\n",
    "number_of_epochs = 1 # how is every sample used for pass/forward/backward\n",
    "\n",
    "# Parameters\n",
    "train_data_path = \"./data/drugLibTrain_raw.tsv\" # please use relative path like this\n",
    "test_data_path = \"./data/drugLibTest_raw.tsv\" # please use relative path like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features =  'commentsReview'\n",
    "\n",
    "###########################################\n",
    "################ Load Data ################\n",
    "###########################################\n",
    "# load data\n",
    "train_data = pd.read_csv(train_data_path, sep='\\t')\n",
    "test_data = pd.read_csv(test_data_path, sep='\\t')\n",
    "# drop nans\n",
    "train_data.dropna(subset = [input_features], inplace=True)\n",
    "test_data.dropna(subset = [input_features], inplace=True)\n",
    "# lowercase all comments\n",
    "train_data[input_features] = train_data[input_features].str.lower()\n",
    "test_data[input_features] = test_data[input_features].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words 11584\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "################ Create directory for words ################\n",
    "############################################################\n",
    "# merge data\n",
    "df_data =  pd.concat([train_data,test_data], axis=0)\n",
    "# create dictonary\n",
    "dictonary_words = df_data[\"commentsReview\"].apply(nltk.word_tokenize)\n",
    "dictonary_words = dictonary_words.values.tolist()\n",
    "# flat lists\n",
    "dictonary_words = [item for sublist in dictonary_words for item in sublist]\n",
    "# drop duplicates\n",
    "dictonary_words = list(set(dictonary_words))\n",
    "# number of all words\n",
    "dict_size = len(dictonary_words)\n",
    "\n",
    "print(f\"Number of words {dict_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "################ Tokenization ################\n",
    "##############################################\n",
    "train_data_tokenized:pd.DataFrame = train_data[\"commentsReview\"].apply(nltk.word_tokenize)\n",
    "test_data_tokenized:pd.DataFrame = test_data[\"commentsReview\"].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>1856</td>\n",
       "      <td>augmentin</td>\n",
       "      <td>3</td>\n",
       "      <td>Moderately Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>tonsilitis</td>\n",
       "      <td>Cleared up most of the symptoms for the 10 day...</td>\n",
       "      <td>None. Actually felt pretty good compared to of...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>2279</td>\n",
       "      <td>lexapro</td>\n",
       "      <td>7</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>depression/anxiety</td>\n",
       "      <td>Depression lessened considerably after 6-8 wee...</td>\n",
       "      <td>Several side effects when initially starting t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 urlDrugName  rating           effectiveness  \\\n",
       "1078        1856   augmentin       3    Moderately Effective   \n",
       "1641        2279     lexapro       7  Considerably Effective   \n",
       "\n",
       "                sideEffects           condition  \\\n",
       "1078        No Side Effects          tonsilitis   \n",
       "1641  Moderate Side Effects  depression/anxiety   \n",
       "\n",
       "                                         benefitsReview  \\\n",
       "1078  Cleared up most of the symptoms for the 10 day...   \n",
       "1641  Depression lessened considerably after 6-8 wee...   \n",
       "\n",
       "                                      sideEffectsReview  \\\n",
       "1078  None. Actually felt pretty good compared to of...   \n",
       "1641  Several side effects when initially starting t...   \n",
       "\n",
       "                                         commentsReview  \n",
       "1078  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1641  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################\n",
    "################ Word Encoding (Bag of words) ################\n",
    "##############################################################\n",
    "def to_bow(dataset):\n",
    "    '''\n",
    "    @param dataset which should be considered (train or test)\n",
    "    @return new column for dataset with sentence/word-encoded cells\n",
    "\n",
    "    For each cell in column of interest, following is performed:\n",
    "    (1) cell contains sentence\n",
    "    (2) sentence is tokenized --> produces array of words/tokens\n",
    "    (3) create array A with len(dict_size) \n",
    "    (4) for each token count occurance \n",
    "    (5) A[index of token t in dict] = occurance of t\n",
    "    '''\n",
    "    new_col = []\n",
    "\n",
    "    # for each row\n",
    "    for _, row in dataset.iterrows():\n",
    "        tokenized = nltk.word_tokenize(row[input_features])\n",
    "        array = np.zeros(shape=dict_size)\n",
    "\n",
    "        # for each word in a setence\n",
    "        for word in tokenized:\n",
    "            i_hot = dictonary_words.index(word)\n",
    "            array[i_hot] = array[i_hot] + 1\n",
    "        new_col.append(array)\n",
    "    \n",
    "    return new_col\n",
    "\n",
    "\n",
    "test_data[input_features] =  to_bow(test_data)\n",
    "train_data[input_features] =  to_bow(train_data)\n",
    "train_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_actual, y_pred):\n",
    "\t'''\tcalculate squared errorr'''\n",
    "\treturn (y_actual-y_pred)**2\n",
    "\n",
    "\n",
    "def derivation_of_loss_function(y_actual, y_pred):\n",
    "\t'''derivative of squared error'''\n",
    "\treturn -2*(y_actual-y_pred)\n",
    "\n",
    "\n",
    "def activation_function(z):\n",
    "\t'''\n",
    "\tsigmoid-function is used as activation function for hidden-layers\n",
    "\t'''\n",
    "\treturn 1/(1 + np.exp(-z))\n",
    "\n",
    "def reLU(z):\n",
    "    '''\n",
    "\treLU is used as activation for output-layer\n",
    "\t'''\n",
    "    return np.maximum(0.0, z)\n",
    "\n",
    "def forward_pass(data):\n",
    "\t# Input --> Hidden-1\n",
    "\tz0 = np.dot(data, w_b['L0_w'].T) + w_b['L0_b'].T\n",
    "\ta0 = activation_function(z0)\n",
    "\n",
    "\t# Hidden-1 --> Hidden-2\n",
    "\tz1 = np.dot(a0, w_b['L1_w'].T) + w_b['L1_b'].T\n",
    "\ta1 = activation_function(z1)\n",
    "\n",
    "\n",
    "\t# LayerHidden2 --> LayerOutput\n",
    "\tz2 = np.dot(a1, w_b['L2_w'].T) + w_b['L2_b'].T\n",
    "\ty_pred = reLU(z2)\n",
    "\n",
    "\tresults={\n",
    "\t\t\"a0\": a0,\n",
    "\t\t\"a1\": a1,\n",
    "\t\t\"y_pred\": y_pred[0][0],\n",
    "\t}\n",
    "\treturn results\n",
    "\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def backward_pass(input_data, forward_results, loss):\n",
    "\t'''calculate error and update weights'''\n",
    "\t\n",
    "\tdelta_output = loss\n",
    "\tw_b['L2_w'] -= learning_rate * np.dot(delta_output.T, forward_results['a1']) \n",
    "\tw_b['L2_b'] -= learning_rate * np.sum(delta_output, keepdims=True)\n",
    "\n",
    "\tdelta_z2 = np.dot(delta_output, w_b['L2_w'])\n",
    "\tdelta_a1 = delta_z2 * derivation_of_activation_function(forward_results['a1'])\n",
    "\tw_b['L1_w'] -= learning_rate * np.dot(delta_a1.T, forward_results['a0']) \n",
    "\tw_b['L1_b'] -= learning_rate * np.sum(delta_a1, keepdims=True)\n",
    "\n",
    "\tdelta_z1 = np.dot(delta_a1, w_b['L1_w'])\n",
    "\tdelta_a0 = delta_z1 * derivation_of_activation_function(forward_results['a0'])\n",
    "\n",
    "\n",
    "\tw_b['L0_w'] -= learning_rate * np.dot(delta_a0.T, np.array([input_data]))\n",
    "\tw_b['L1_b'] -= learning_rate * np.sum(delta_a0, keepdims=True)\n",
    "\tpass\n",
    "\n",
    "\n",
    "def derivation_of_activation_function(x):\n",
    "\t'''derivation of sigmoid'''\n",
    "\treturn activation_function(x) * (1 - activation_function(x))\n",
    "\n",
    "\n",
    "def train(train_data, train_labels, valid_data, valid_labels):\n",
    "\tlosses =[]\n",
    "\tfor epoch in range(number_of_epochs):\n",
    "\t\tindex = 0\n",
    "\n",
    "\t\t# Same thing about [hidden_layers] mentioned above is valid here also\n",
    "\t\tfor encoded_sentence, y_rating in zip(train_data, train_labels):\n",
    "\t\t\tforward_results = forward_pass(encoded_sentence)\n",
    "\t\t\tderivation = derivation_of_loss_function(y_rating, forward_results[\"y_pred\"])\n",
    "\t\t\tbackward_pass(encoded_sentence , forward_results, derivation)\n",
    "\t\t\tloss = loss_function(y_rating, forward_results[\"y_pred\"])\n",
    "\t\t\tif index % 400 == 0: # at each 400th sample, we run validation set to see our model's improvements\n",
    "\t\t\t\tloss = test(valid_data, valid_labels)\n",
    "\t\t\t\tlosses.append(loss)\n",
    "\t\t\t\tprint(f\"Epoch= {epoch}, Coverage={round(100*(index/len(train_data)),2)}%, Loss= {round(loss,2)}\")\n",
    "\n",
    "\t\t\tindex += 1\n",
    "\n",
    "\treturn losses\n",
    "\n",
    "\n",
    "\n",
    "def test(test_data, test_y_ratings):\n",
    "\tavg_loss = 0\n",
    "\tpredictions = []\n",
    "\tlabels = []\n",
    "\n",
    "\tfor encoded_sentence, y_rating in zip(test_data, test_y_ratings):\n",
    "\t\tforward_results = forward_pass(encoded_sentence)\n",
    "\t\tpredictions.append(forward_results[\"y_pred\"])\n",
    "\t\tlabels.append(y_rating)\n",
    "\t\tavg_loss += np.sum(loss_function(y_rating, forward_results[\"y_pred\"]))\n",
    "\n",
    "\treturn avg_loss / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0, Coverage=0.0%, Loss= 53.07\n",
      "Epoch= 0, Coverage=17.21%, Loss= 10.16\n",
      "Epoch= 0, Coverage=34.42%, Loss= 9.44\n",
      "Epoch= 0, Coverage=51.64%, Loss= 9.48\n",
      "Epoch= 0, Coverage=68.85%, Loss= 9.22\n",
      "Epoch= 0, Coverage=86.06%, Loss= 9.18\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "################ Create datasets ################\n",
    "#################################################\n",
    "# split into train & test    and    feature & y columns\n",
    "train_x = train_data[input_features]\n",
    "train_y = train_data['rating']\n",
    "test_x = test_data[input_features]\n",
    "test_y = test_data['rating']\n",
    "\n",
    "\n",
    "##################################################################\n",
    "################ split into validation & training ################\n",
    "##################################################################\n",
    "# Split training data into [a] Training (75%) and [b] validation (25%)\n",
    "valid_x = np.asarray(train_x[int(0.75*len(train_x)):-1])\n",
    "valid_y = np.asarray(train_y[int(0.75*len(train_y)):-1])\n",
    "train_x = np.asarray(train_x[0:int(0.75*len(train_x))])\n",
    "train_y = np.asarray(train_y[0:int(0.75*len(train_y))])\n",
    "\n",
    "# Hyperparamater\n",
    "num_neurons_in_h1 = 33\n",
    "num_neurons_in_h2 = 3\n",
    "\n",
    "\n",
    "w_b = {\n",
    "    # Input-Layer -> H1\n",
    "    \"L0_w\" : np.random.randn(num_neurons_in_h1, dict_size) , \n",
    "    \"L0_b\": np.ones((num_neurons_in_h1, 1)) * 0.01,\n",
    "\n",
    "    # H1 -> H2\n",
    "    \"L1_w\" : np.random.randn(num_neurons_in_h2, num_neurons_in_h1), \n",
    "    \"L1_b\": np.ones((num_neurons_in_h2, 1)) * 0.01,\n",
    "\n",
    "    # H2 -> Output-Layer\n",
    "    \"L2_w\" : np.random.randn(output_size, num_neurons_in_h2), \n",
    "    \"L2_b\": np.ones((output_size, 1)) * 0.01,\n",
    "}\n",
    "\n",
    "\n",
    "#######################################\n",
    "################ train ################\n",
    "#######################################\n",
    "list_losses= train(train_x, train_y, valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb31910b7f0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(0,len(list_losses))\n",
    "y = list_losses\n",
    "\n",
    "plt.xlabel(\"Validation set run (after 400 new samples)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.97200182883319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f81ca3d73f16c3fc9f14852cf151c9505b747a4fab6a8a5fe026d3697dfd654b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('study-lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
