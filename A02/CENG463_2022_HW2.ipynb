{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Joel Amarou Heuer\n",
    "\n",
    "Student ID: 202102201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Hyper)Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Hyperparameters\n",
    "# input_size = \n",
    "output_size = 10 # -> number of neurons in output-layer (= for each possible rating?)\n",
    "# [hidden_layers_sizes] = \n",
    "# learning_rate = \n",
    "number_of_epochs = 1 # how is every sample used for pass/forward/backward\n",
    "\n",
    "# Parameters\n",
    "train_data_path = \"./data/drugLibTrain_raw.tsv\" # please use relative path like this\n",
    "test_data_path = \"./data/drugLibTest_raw.tsv\" # please use relative path like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "EXAMPLE\n",
    "\n",
    "inputs = [1,2,3,4]    das sind 4 Eingaben, also entweder \n",
    "\t\t\t\t\t\t-> 4 Features fÃ¼r Input-Layer oder \n",
    "\t\t\t\t\t\t-> 4 Neuronen der davorigen Layer\n",
    "\n",
    "weights = [\n",
    "\t\t\t[w11,w12,w13,w14]       -> Neuoron1 hat 4 Weights, also von jedem Neuron der davorigen Schicht eins\n",
    "\t\t\t[w21,w22,w23,w24]\t\t-> Neuoron2 hat 4 Weights, also von jedem Neuron der davorigen Schicht eins\n",
    "\t\t]\n",
    "\t  2x4\n",
    "\t#NeuronenProHiddenLayer x #Inputs\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def forward_pass(data):\n",
    "\t'''\n",
    "\t@param data is comment/review in string format\n",
    "\t-> for a string s, one-hot-encoding makes matrix with dimensions:     {#words-in-string}         x     {#all-words-in-dataset = input-size}\n",
    "\n",
    "\tmultiply with weights-matrix, which has dimensions:\t\t\t\t:     {#neuron-in-hidden-layeri} x     {#input-size}\n",
    "\n",
    "\n",
    "\tFormula1: \tweights     *      inputs       +     biases\n",
    "\t       \t    {#n/l}x{#ip}       {#ip}{??}          {#ip}{??}\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "\t\n",
    "\t'''\n",
    "\n",
    "\tprint(data)\n",
    "\t# LayerInput --> LayerHidden1\n",
    "\n",
    "\n",
    "\t# LayerHidden2 --> LayerHidden2\n",
    "\n",
    "\t# LayerHidden2 --> LayerOutput\n",
    "\tpass\n",
    "\n",
    "\n",
    "def train(train_data, train_labels, valid_data, valid_labels):\n",
    "\tfor epoch in range(number_of_epochs):\n",
    "\t\tindex = 0\n",
    "\n",
    "\t\t# Same thing about [hidden_layers] mentioned above is valid here also\n",
    "\t\tfor data, labels in zip(train_data, train_labels):\n",
    "\t\t\tpredictions  = forward_pass(data)\n",
    "\t\t\tbreak\n",
    "\t\t\t#loss_signals = derivation_of_loss_function(labels, predictions)\n",
    "\t\t\t#backward_pass(data, [hidden_layers], predictions, loss_signals)\n",
    "\t\t\t#loss = loss_function(labels, predictions)\n",
    "\n",
    "\t\t\t#if index % 2000 == 0: # at each 2000th sample, we run validation set to see our model's improvements\n",
    "\t\t\t#\taccuracy, loss = test(valid_data, valid_labels)\n",
    "\t\t\t#\tprint(\"Epoch= \"+str(epoch)+\", Coverage= %\"+ str(100*(index/len(train_data))) + \", Accuracy= \"+ str(accuracy) + \", Loss= \" + str(loss))\n",
    "#\n",
    "\t\t\t#index += 1\n",
    "\n",
    "#   return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "147",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 147",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/korosu/git/university/CENG-463-ML/A02/CENG463_2022_HW2.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/korosu/git/university/CENG-463-ML/A02/CENG463_2022_HW2.ipynb#ch0000009?line=23'>24</a>\u001b[0m \u001b[39m# add 1's into one-hot-matrix\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/korosu/git/university/CENG-463-ML/A02/CENG463_2022_HW2.ipynb#ch0000009?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(train_y)) :    \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/korosu/git/university/CENG-463-ML/A02/CENG463_2022_HW2.ipynb#ch0000009?line=25'>26</a>\u001b[0m     new_train_y[i][train_y[i]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/korosu/git/university/CENG-463-ML/A02/CENG463_2022_HW2.ipynb#ch0000009?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(test_y)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/korosu/git/university/CENG-463-ML/A02/CENG463_2022_HW2.ipynb#ch0000009?line=28'>29</a>\u001b[0m     new_test_y[i][test_y[i]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=954'>955</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=956'>957</a>\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=957'>958</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=959'>960</a>\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=960'>961</a>\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=961'>962</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=962'>963</a>\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=1065'>1066</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=1067'>1068</a>\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=1068'>1069</a>\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/series.py?line=1069'>1070</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/korosu/miniconda3/envs/study-lab/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 147"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "input_features =  'commentsReview'\n",
    "\n",
    "train_data = pd.read_csv(train_data_path, sep='\\t')\n",
    "test_data = pd.read_csv(test_data_path, sep='\\t')\n",
    "\n",
    "# drop nans\n",
    "train_data.dropna(subset = [input_features], inplace=True)\n",
    "test_data.dropna(subset = [input_features], inplace=True)\n",
    "\n",
    "\n",
    "# split feature and y columns\n",
    "train_x = train_data[input_features]\n",
    "train_y = train_data['rating']\n",
    "test_x = test_data[input_features]\n",
    "test_y = test_data['rating']\n",
    "\n",
    "\n",
    "# ONE-HOT for classes 1-10\n",
    "# creating one-hot vector notation of labels. (Labels are given numeric in the dataset)\n",
    "new_train_y = np.zeros(shape=(len(train_y), output_size))\n",
    "new_test_y = np.zeros(shape=(len(test_y), output_size))\n",
    "\n",
    "# add 1's into one-hot-matrix\n",
    "for i in range(len(train_y)) :    \n",
    "    new_train_y[i][train_y[i]-1] = 1\n",
    "\n",
    "for i in range(len(test_y)):\n",
    "    new_test_y[i][test_y[i]-1] = 1\n",
    "\n",
    "train_y = new_train_y\n",
    "test_y = new_test_y\n",
    "\n",
    "# Split training data into [a] Training (75%) and [b] validation (25%)\n",
    "valid_x = np.asarray(train_x[int(0.75*len(train_x)):-1])\n",
    "valid_y = np.asarray(train_y[int(0.75*len(train_y)):-1])\n",
    "train_x = np.asarray(train_x[0:int(0.75*len(train_x))])\n",
    "train_y = np.asarray(train_y[0:int(0.75*len(train_y))])\n",
    "\n",
    "# TODO\n",
    "train(train_x, train_y, valid_x, valid_y)\n",
    "#print(\"Test Scores:\")\n",
    "#print(test(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/korosu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/tmp/ipykernel_9813/2729530844.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_data =  train_data.append(test_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13480"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(train_data_path, sep='\\t')\n",
    "test_data = pd.read_csv(test_data_path, sep='\\t')\n",
    "\n",
    "df_data =  train_data.append(test_data)\n",
    "\n",
    "df_data[\"commentsReview\"].isnull().values.sum()\n",
    "df_data.dropna(subset = [\"commentsReview\"], inplace=True)\n",
    "\n",
    "\n",
    "dictonary_words = df_data[\"commentsReview\"].apply(nltk.word_tokenize)\n",
    "dictonary_words = dictonary_words.values.tolist()\n",
    "# flat lists\n",
    "dictonary_words = [item for sublist in dictonary_words for item in sublist]\n",
    "dictonary_words = list(set(dictonary_words))\n",
    "len(dictonary_words)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f81ca3d73f16c3fc9f14852cf151c9505b747a4fab6a8a5fe026d3697dfd654b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('study-lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
