{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Joel Amarou Heuer\n",
    "\n",
    "Student ID: 202102201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/korosu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math     \n",
    "\n",
    "# for tokenization use nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Hyper)Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Hyperparameters\n",
    "output_size = 1 # -> number of neurons in output-layer (= for each possible rating?)\n",
    "learning_rate = 0.01\n",
    "number_of_epochs = 1 # how is every sample used for pass/forward/backward\n",
    "\n",
    "\n",
    "# Parameters\n",
    "train_data_path = \"./data/drugLibTrain_raw.tsv\" # please use relative path like this\n",
    "test_data_path = \"./data/drugLibTest_raw.tsv\" # please use relative path like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features =  'commentsReview'\n",
    "\n",
    "###########################################\n",
    "################ Load Data ################\n",
    "###########################################\n",
    "# load data\n",
    "train_data = pd.read_csv(train_data_path, sep='\\t')\n",
    "test_data = pd.read_csv(test_data_path, sep='\\t')\n",
    "# drop nans\n",
    "train_data.dropna(subset = [input_features], inplace=True)\n",
    "test_data.dropna(subset = [input_features], inplace=True)\n",
    "# lowercase all comments\n",
    "train_data[input_features] = train_data[input_features].str.lower()\n",
    "test_data[input_features] = test_data[input_features].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words 11584\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "################ Create directory for words ################\n",
    "############################################################\n",
    "# merge data\n",
    "df_data =  pd.concat([train_data,test_data], axis=0)\n",
    "# create dictonary\n",
    "dictonary_words = df_data[\"commentsReview\"].apply(nltk.word_tokenize)\n",
    "dictonary_words = dictonary_words.values.tolist()\n",
    "# flat lists\n",
    "dictonary_words = [item for sublist in dictonary_words for item in sublist]\n",
    "# drop duplicates\n",
    "dictonary_words = list(set(dictonary_words))\n",
    "# number of all words\n",
    "dict_size = len(dictonary_words)\n",
    "\n",
    "print(f\"Number of words {dict_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "################ Tokenization ################\n",
    "##############################################\n",
    "train_data_tokenized:pd.DataFrame = train_data[\"commentsReview\"].apply(nltk.word_tokenize)\n",
    "test_data_tokenized:pd.DataFrame = test_data[\"commentsReview\"].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>2119</td>\n",
       "      <td>renova</td>\n",
       "      <td>7</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>melasma</td>\n",
       "      <td>Faint pigmentation started to disappear after ...</td>\n",
       "      <td>Sever redness and scaling occurred especially ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>3602</td>\n",
       "      <td>retin-a</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>acne</td>\n",
       "      <td>My acne has completely dminished...i have the ...</td>\n",
       "      <td>Peeling, dryness, sun sensitivity</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 urlDrugName  rating           effectiveness  \\\n",
       "2653        2119      renova       7  Considerably Effective   \n",
       "618         3602     retin-a       9        Highly Effective   \n",
       "\n",
       "                sideEffects condition  \\\n",
       "2653    Severe Side Effects   melasma   \n",
       "618   Moderate Side Effects      acne   \n",
       "\n",
       "                                         benefitsReview  \\\n",
       "2653  Faint pigmentation started to disappear after ...   \n",
       "618   My acne has completely dminished...i have the ...   \n",
       "\n",
       "                                      sideEffectsReview  \\\n",
       "2653  Sever redness and scaling occurred especially ...   \n",
       "618                   Peeling, dryness, sun sensitivity   \n",
       "\n",
       "                                         commentsReview  \n",
       "2653  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "618   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################\n",
    "################ Word Encoding (Bag of words) ################\n",
    "##############################################################\n",
    "def to_bow(dataset):\n",
    "    '''\n",
    "    @param dataset which should be considered (train or test)\n",
    "    @return new column for dataset with sentence/word-encoded cells\n",
    "\n",
    "    For each cell in column of interest, following is performed:\n",
    "    (1) cell contains sentence\n",
    "    (2) sentence is tokenized --> produces array of words/tokens\n",
    "    (3) create array A with len(dict_size) \n",
    "    (4) for each token count occurance \n",
    "    (5) A[index of token t in dict] = occurance of t\n",
    "    '''\n",
    "    new_col = []\n",
    "\n",
    "    # for each row\n",
    "    for _, row in dataset.iterrows():\n",
    "        tokenized = nltk.word_tokenize(row[input_features])\n",
    "        array = np.zeros(shape=dict_size)\n",
    "\n",
    "        # for each word in a setence\n",
    "        for word in tokenized:\n",
    "            i_hot = dictonary_words.index(word)\n",
    "            array[i_hot] = array[i_hot] + 1\n",
    "        new_col.append(array)\n",
    "    \n",
    "    return new_col\n",
    "\n",
    "\n",
    "test_data[input_features] =  to_bow(test_data)\n",
    "train_data[input_features] =  to_bow(train_data)\n",
    "train_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10223/3682247787.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/2324\n",
      "800/2324\n",
      "1200/2324\n",
      "1600/2324\n",
      "2000/2324\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "################ Create datasets ################\n",
    "#################################################\n",
    "# split into train & test    and    feature & y columns\n",
    "train_x = train_data[input_features]\n",
    "train_y = train_data['rating']\n",
    "test_x = test_data[input_features]\n",
    "test_y = test_data['rating']\n",
    "\n",
    "\n",
    "##################################################################\n",
    "################ split into validation & training ################\n",
    "##################################################################\n",
    "# Split training data into [a] Training (75%) and [b] validation (25%)\n",
    "valid_x = np.asarray(train_x[int(0.75*len(train_x)):-1])\n",
    "valid_y = np.asarray(train_y[int(0.75*len(train_y)):-1])\n",
    "train_x = np.asarray(train_x[0:int(0.75*len(train_x))])\n",
    "train_y = np.asarray(train_y[0:int(0.75*len(train_y))])\n",
    "\n",
    "\n",
    "'''WIP'''\n",
    "# Hyperparamater\n",
    "num_neurons_in_h1 = 20\n",
    "num_neurons_in_h2 = 10\n",
    "\n",
    "w_b = {\n",
    "    # Input-Layer -> H1\n",
    "    \"L0_w\" : np.random.randn(num_neurons_in_h1, dict_size), \n",
    "    \"L0_b\": np.ones((num_neurons_in_h1, 1)) * 0.01,\n",
    "\n",
    "    # H1 -> H2\n",
    "    \"L1_w\" : np.random.randn(num_neurons_in_h2, num_neurons_in_h1), # WIP\n",
    "    \"L1_b\": np.ones((num_neurons_in_h2, 1)) * 0.01,\n",
    "\n",
    "    # H2 -> Output-Layer\n",
    "    \"L2_w\" : np.random.randn(output_size, num_neurons_in_h2), # WIP\n",
    "    \"L2_b\": np.ones((output_size, 1)) * 0.01,\n",
    "}\n",
    "\n",
    "\n",
    "#######################################\n",
    "################ train ################\n",
    "#######################################\n",
    "# TODO\n",
    "losses= train(train_x, train_y, valid_x, valid_y)\n",
    "\n",
    "######################################\n",
    "################ test ################\n",
    "######################################\n",
    "# TODO \n",
    "#print(\"Test Scores:\")\n",
    "#print(test(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdc0ca25d00>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(0,len(losses))\n",
    "y = losses\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def derivation_of_loss_function(y_actual, y_pred):\n",
    "\t'''\n",
    "\tcalculate squared error\n",
    "\t'''\n",
    "\treturn (y_actual-y_pred)**2\n",
    "\n",
    "\n",
    "def activation_function(z):\n",
    "\t'''\n",
    "\tsigmoid-function is used as activation function for hidden-layers\n",
    "\t'''\n",
    "\treturn 1/(1 + np.exp(-z))\n",
    "\n",
    "def reLU(z):\n",
    "    '''\n",
    "\treLU is used as activation for output-layer\n",
    "\t'''\n",
    "    return np.maximum(0.0, z)\n",
    "\n",
    "def forward_pass(data):\n",
    "\t# Input --> Hidden-1\n",
    "\tz0 = np.dot(data, w_b['L0_w'].T) + w_b['L0_b'].T\n",
    "\ta0 = activation_function(z0)\n",
    "\n",
    "\t# Hidden-1 --> Hidden-2\n",
    "\tz1 = np.dot(a0, w_b['L1_w'].T) + w_b['L1_b'].T\n",
    "\ta1 = activation_function(z1)\n",
    "\n",
    "\n",
    "\t# LayerHidden2 --> LayerOutput\n",
    "\tz2 = np.dot(a1, w_b['L2_w'].T) + w_b['L2_b'].T\n",
    "\ty_pred = reLU(z2)\n",
    "\n",
    "\tresults={\n",
    "\t\t\"a0\": a0,\n",
    "\t\t\"a1\": a1,\n",
    "\t\t\"y_pred\": y_pred[0][0],\n",
    "\t}\n",
    "\treturn results\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def derivation_of_loss_function(y_actual, y_pred):\n",
    "\t'''calculate squared error'''\n",
    "\treturn (y_actual-y_pred)**2\n",
    "\n",
    "\n",
    "def backward_pass(input_data, forward_results, loss):\n",
    "\t'''calculate error and update weights'''\n",
    "\t\n",
    "\tdelta_output = loss\n",
    "\tw_b['L2_w'] -= learning_rate * np.dot(delta_output.T, forward_results['a1']) \n",
    "\tw_b['L2_b'] -= learning_rate * np.sum(delta_output, keepdims=True)\n",
    "\n",
    "\tdelta_z2 = np.dot(delta_output, w_b['L2_w'])\n",
    "\tdelta_a1 = delta_z2 * derivation_of_activation_function(forward_results['a1'])\n",
    "\tw_b['L1_w'] -= learning_rate * np.dot(delta_a1.T, forward_results['a0']) \n",
    "\tw_b['L1_b'] -= learning_rate * np.sum(delta_a1, keepdims=True)\n",
    "\n",
    "\tdelta_z1 = np.dot(delta_a1, w_b['L1_w'])\n",
    "\tdelta_a0 = delta_z1 * derivation_of_activation_function(forward_results['a0'])\n",
    "\n",
    "\n",
    "\tw_b['L0_w'] -= learning_rate * np.dot(delta_a0.T, np.array([input_data]))\n",
    "\tw_b['L1_b'] -= learning_rate * np.sum(delta_a0, keepdims=True)\n",
    "\tpass\n",
    "\n",
    "\n",
    "def derivation_of_activation_function(x):\n",
    "\t'''derivation of sigmoid'''\n",
    "\treturn activation_function(x) * (1 - activation_function(x))\n",
    "\n",
    "def loss_function(y_actual, y_pred):\n",
    "\t''' squared error i guess ''' \n",
    "\treturn (y_actual-y_pred)**2\n",
    "\n",
    "\n",
    "\n",
    "def train(train_data, train_labels, valid_data, valid_labels):\n",
    "\tlosses =[]\n",
    "\tfor epoch in range(number_of_epochs):\n",
    "\t\tindex = 0\n",
    "\n",
    "\t\t# Same thing about [hidden_layers] mentioned above is valid here also\n",
    "\t\tfor encoded_sentence, y_rating in zip(train_data, train_labels):\n",
    "\t\t\tforward_results = forward_pass(encoded_sentence)\n",
    "\t\t\tderivation = derivation_of_loss_function(y_rating, forward_results[\"y_pred\"])\n",
    "\t\t\tbackward_pass(encoded_sentence , forward_results, derivation)\n",
    "\t\t\tloss = loss_function(y_rating, forward_results[\"y_pred\"])\n",
    "\t\t\tlosses.append(loss)\n",
    "\t\t\t\n",
    "\t\t\tif index % 400 == 0: # at each 400th sample, we run validation set to see our model's improvements\n",
    "\t\t\t\tprint(f\"{index}/{len(train_data)}\")\t\t\t\t\n",
    "# \t\t\t\taccuracy, loss = test(valid_data, valid_labels)\n",
    "#\t\t\t\tprint(\"Epoch= \"+str(epoch)+\", Coverage= %\"+ str(100*(index/len(train_data))) + \", Accuracy= \"+ str(accuracy) + \", Loss= \" + str(loss))\n",
    "#\n",
    "\t\t\tindex += 1\n",
    "#\n",
    "\treturn losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f81ca3d73f16c3fc9f14852cf151c9505b747a4fab6a8a5fe026d3697dfd654b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('study-lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
